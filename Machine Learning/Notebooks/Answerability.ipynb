{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_xlQjN5Nk50",
        "outputId": "6248c759-6df5-4d30-8a3e-69bb2fb871cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GO1KG4dyTDs",
        "outputId": "4d39d62e-cf5c-44bd-84d1-e580b137422e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/MyDrive/data.zip\n",
            "  inflating: train.csv               \n",
            "  inflating: __MACOSX/._train.csv    \n",
            "  inflating: test.csv                \n",
            "  inflating: __MACOSX/._test.csv     \n",
            "  inflating: val.csv                 \n",
            "  inflating: __MACOSX/._val.csv      \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DfBWTXZPxxj"
      },
      "source": [
        "# Data Processing \n",
        "We convert the answer into the exact text from the document (Extractive), getting the index of the starting and ending answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5RDls-1i2SL"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers \n",
        "!pip install -q sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYW9KtD5j-Ht"
      },
      "outputs": [],
      "source": [
        "from ast import literal_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUnRpHJXcRjq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoTokenizer\n",
        "from nltk import tokenize\n",
        "import numpy as np\n",
        "import pickle\n",
        "import transformers\n",
        "import torch\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words ='english')\n",
        "sentence_t = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY7EmGop3ILU",
        "outputId": "12549ba9-8640-4a11-8b46-48cf3ec88646"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abLOLuSoiwsV"
      },
      "outputs": [],
      "source": [
        "def add_features(df):\n",
        "  #HELPERS\n",
        "  def intersec(q,r):\n",
        "    return len([x for x in q if x in r])\n",
        "  \n",
        "  def vectorize(text):\n",
        "    return tfidf_vectorizer.transform([text]).toarray()[0]\n",
        "\n",
        "  def tokenize(text):\n",
        "    return tokenizer(text,max_length=512,truncation=True).get('input_ids')\n",
        "  \n",
        "  def sentenceTransform(text):\n",
        "    return sentence_t.encode(text)\n",
        "\n",
        "  def cosine_similarity(a,b):\n",
        "    return np.dot(a,b)/(np.linalg.norm(a) * np.linalg.norm(b))\n",
        "  \n",
        "  def dotproduct(a,b):\n",
        "    return np.dot(a,b)\n",
        "  \n",
        "  def euclid_dist(a,b):\n",
        "    return np.linalg.norm(a-b)\n",
        "  \n",
        "  def sentence_mean_max(model,q,r):\n",
        "    f = dotproduct\n",
        "    vals = [f(q,model(sentence)) for sentence in nltk.tokenize.sent_tokenize(r)]\n",
        "    if not vals:\n",
        "      return pd.Series([np.mean(vals), np.max(vals)])\n",
        "    else:\n",
        "      return pd.Series([[],[]])\n",
        "\n",
        "  df = df.copy()\n",
        "  df['question_ntokens'] = df['questionText'].apply(lambda x:len(tokenize(x)))\n",
        "  df['review_ntokens'] = df['review_snippets'].apply(lambda x:len(tokenize(x)))\n",
        "  df['question_tokens'] = df['questionText'].apply(lambda x:tokenize(x))\n",
        "  df['review_tokens'] = df['review_snippets'].apply(lambda x:tokenize(x))\n",
        "  df['intersec'] = df.apply(lambda row: intersec(row['questionText'], row['review_snippets']),axis=1)\n",
        "  df['intersec_pct'] = df['intersec'] / df['question_ntokens']\n",
        "  df['question_encoded'] = df['questionText'].apply(lambda x: sentenceTransform(x))\n",
        "  df['review_encoded'] = df['review_snippets'].apply(lambda x: sentenceTransform(x))\n",
        "  df['question_tfidf'] = df['questionText'].apply(lambda x: vectorize(x))\n",
        "  df['review_tfidf'] = df['review_snippets'].apply(lambda x: vectorize(x))\n",
        "\n",
        "  for m in ['encoded','tfidf']:\n",
        "    df[f'cosine_sim_{m}'] = df.apply(lambda row: cosine_similarity(row[f'question_{m}'], row[f'review_{m}']),axis =1 )\n",
        "    df[f'dot_prod_{m}'] = df.apply(lambda row: dotproduct(row[f'question_{m}'], row[f'review_{m}']),axis =1 )\n",
        "    df[f'euclid_dist_{m}'] = df.apply(lambda row: euclid_dist(row[f'question_{m}'], row[f'review_{m}']),axis =1 )\n",
        "  df[['sent_max_encoded','sent_mean_encoded']] = df.apply(lambda row: sentence_mean_max(sentenceTransform, row['question_encoded'], row['review_snippets']),axis =1 )\n",
        "  df[['sent_max_tfidf','sent_mean_tfidf']] = df.apply(lambda row: sentence_mean_max(vectorize, row['question_tfidf'], row['review_snippets']),axis =1 )\n",
        "\n",
        "  df.drop(['question_tokens','review_tokens','question_encoded','review_encoded','question_tfidf','review_tfidf'],axis =1 , inplace = True)\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMoB4BP8i0CT"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('train.csv').sample(frac = 1).dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ps1Hhs-rOj6P"
      },
      "outputs": [],
      "source": [
        "train_df = pd.concat([train_df[train_df['is_answerable'] == 1].iloc[:4000],train_df[train_df['is_answerable'] != 1].iloc[:4000]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E_90TnlQOeZ"
      },
      "outputs": [],
      "source": [
        "train_df = train_df.sample(frac =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JFZXT85jqGK"
      },
      "outputs": [],
      "source": [
        "X = train_df.drop('is_answerable',axis=1)\n",
        "y = train_df['is_answerable'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBQr7xPHjP_X",
        "outputId": "6c200411-2e6e-412c-9db8-22a998654020"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TfidfVectorizer(stop_words='english')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf_vectorizer.fit(X['questionText'].tolist() + X['review_snippets'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "siDXsumFdPpE"
      },
      "outputs": [],
      "source": [
        "def feature_generations(df):\n",
        "  df = df[['review_snippets','questionText','is_answerable']].copy()\n",
        "  df['review_snippets'] = df['review_snippets'].apply(lambda x: '    '.join(literal_eval(x))) #4 spaces\n",
        "  X = df.drop('is_answerable',axis=1)\n",
        "  y = df['is_answerable'].values\n",
        "  X = add_features(X)\n",
        "  return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jgj6fB8zkMoZ",
        "outputId": "c87b83b2-04ea-4719-f81a-d7a7e2a56bfa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-5-0ccfe5ef7dad>:16: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  return np.dot(a,b)/(np.linalg.norm(a) * np.linalg.norm(b))\n"
          ]
        }
      ],
      "source": [
        "X_train,y_train = feature_generations(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ag7o2MRmAPXw"
      },
      "outputs": [],
      "source": [
        "df = X_train\n",
        "df['Y'] = y_train\n",
        "df.to_csv('processed1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aeg7fVlPZmR2"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('processed1.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0XKmHrCX1y3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.15 (main, Nov 24 2022, 08:29:02) \n[Clang 14.0.6 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "6a82152883a9ae0824417df8eee29fc768be135be911d7c9b59fdda4f963266b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
